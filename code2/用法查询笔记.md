> ## 用法查询笔记-Python爬虫精进

## 目标1初窥门径
>### 第0关 认识爬虫
`2019年12月31日` 重新定义网上冲浪
```python
import requests
url = 'http://baidu.com'
res = requests.get(url)
print(res.text)
```

>### 第1关 HTML基础
`2020年1月1日` 课堂: 我也可以写个网页

## 目标二：爬虫小成
>### 第2关 BeautifulSoup
`2020年1月1日` 课堂: 爬虫初体验


### BeautifulSoup怎么用
`BeautifulSoup`库目前已经进阶到第4版（Beautiful Soup 4），由于它不是Python标准库，而是第三方库，需要单独安装它，不过，我们的学习系统已经安装好了。

如果你是在自己的电脑上运行，需要在终端输入一行代码运行：`pip install BeautifulSoup4`。（Mac电脑需要输入`pip3 install BeautifulSoup4`）

- 解析数据

```python
import requests
# 引入BS库，下面的bs4就是beautifulsoup4
from bs4 import BeautifulSoup
res = requests.get('https://localprod.pandateacher.com/python-manuscript/crawler-html/spider-men5.0.html') 
html = res.text
# 把网页解析为BeautifulSoup对象
soup = BeautifulSoup(html,'html.parser') 
print(soup)  #输出 <html>...</html>
print(type(soup))  #输出 <class 'bs4.BeautifulSoup'>
```

- 提取数据

我们仍然使用`BeautifulSoup`来提取数据。

又可以分为两部分知识：find()与find_all()，以及Tag对象（标签对象）。

首先，请看举例中括号里的class_，这里有一个下划线，是为了和python语法中的类 class区分，避免程序冲突。当然，除了用class属性去匹配，还可以使用其它属性，比如style属性等。

数据类型是<class 'bs4.element.ResultSet>， 前面说过可以把它当做列表list来看待。

>### 第3关 BeautifulSoup实践
`2020年1月1日` 课堂：解密吴氏私厨

>### 第4关 json
`2020年1月1日` 课堂：寻找周杰伦

>### 第5关 带参数请求数据
`2020年1月1日` 课堂：狂热粉丝

>### 第6关 csv&excel
`2020年1月1日` 课堂：爬到的数据存哪里？

>### 第7关 爬取知乎文章
`2020年1月1日` 课堂：复习：温故而知新

## 目标三：更上层楼

>### 第8关 cookies
`2020年1月1日` 课堂：带着小饼干登录

>### 第9关 Selenium
`2020年1月1日` 课堂：指挥浏览器自动工作

>### 第10关 定时与邮件
`2020年1月1日` 课堂：让爬虫按时向你汇报

## 目标四：拨云见日
>### 第11关 协程
`2020年1月1日` 课堂：建立爬虫军队

>### 第12关 协程实践
`2020年1月1日` 课堂：吃什么不会胖？

>### 第13关 Scrapy框架
`2020年1月1日` 课堂：各司其职的爬虫公司

>### 第14关 Scrapy实操
`2020年1月1日` 课堂：出任爬虫公司CEO

>### 第15关 复习与反爬虫
`2020年1月1日` 课堂：逢山开路与不甘庸碌
